{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Preprocessing Pipeline\n",
    "This notebook contains the complete, integrated preprocessing pipeline for the credit card fraud detection dataset. It combines the work of all group members."
   ],
   "id": "1fe08776f26b0d99"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T06:57:20.782346Z",
     "start_time": "2025-09-18T06:57:20.769907Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Define the path for saving visualizations\n",
    "output_viz_path = \"../results/eda_visualizations/\"\n",
    "if not os.path.exists(output_viz_path):\n",
    "    os.makedirs(output_viz_path)\n",
    "\n",
    "# 1. Load dataset\n",
    "df = pd.read_csv(\"../data/raw/creditcard.csv\")\n",
    "print(\"\n=== Dataset Loaded ===\")\n",
    "print(df.head())\n",
    "\n",
    "# ========================= Kishan Ahamed =========================\n",
    "# 2. Handle missing values\n",
    "print(\"\nMissing values:\n\", df.isnull().sum())\n",
    "if df.isnull().sum().sum() > 0:\n",
    "    print(\"\nHandling missing values...\")\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in ['float64', 'int64']:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "        else:\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "else:\n",
    "    print(\"✅ No missing values found.\")\n",
    "\n",
    "# ========================= Abhinaya Kumar =========================\n",
    "# 3. Encode categorical variables\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "if len(categorical_cols) > 0:\n",
    "    print(f\"\nEncoding categorical variables: {list(categorical_cols)}\")\n",
    "    le = LabelEncoder()\n",
    "    for col in categorical_cols:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "else:\n",
    "    print(\"✅ No categorical variables found.\")\n",
    "\n",
    "# ========================= Lafry =========================\n",
    "# 4. Outlier handling using percentile clipping (1st–99th percentile)\n",
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns.drop('Class', errors='ignore')\n",
    "print(f\"\nClipping outliers in {len(num_cols)} numeric features to 1st–99th percentile...\")\n",
    "for col in num_cols:\n",
    "    lower = df[col].quantile(0.01)\n",
    "    upper = df[col].quantile(0.99)\n",
    "    df[col] = np.clip(df[col], lower, upper)\n",
    "print(\"✅ Outlier clipping complete.\")\n",
    "\n",
    "# ========================= Nevin Nijanthan =========================\n",
    "# 5. Feature Engineering (before train/test split) + Feature Selection\n",
    "if 'Amount' in df.columns and 'Time' in df.columns:\n",
    "    df['Amount_per_Time'] = df['Amount'] / (df['Time'] + 1)\n",
    "    print(\"✅ Created new feature: Amount_per_Time\")\n",
    "else:\n",
    "    print(\"⚠️ Skipping feature engineering (Amount/Time not found).\")\n",
    "\n",
    "# Mutual Information Feature Selection\n",
    "X_temp = df.drop('Class', axis=1)\n",
    "y_temp = df['Class']\n",
    "mi_scores = mutual_info_classif(X_temp, y_temp, random_state=42)\n",
    "mi_series = pd.Series(mi_scores, index=X_temp.columns).sort_values(ascending=False)\n",
    "print(\"\nMutual Information Scores:\n\", mi_series)\n",
    "selected_features = mi_series[mi_series > 0].index.tolist()\n",
    "print(\"\nSelected features based on MI (>0):\n\", selected_features)\n",
    "X = df[selected_features]\n",
    "y = df['Class']\n",
    "\n",
    "# Class distribution BEFORE SMOTE\n",
    "print(\"\nClass distribution BEFORE SMOTE:\n\", y.value_counts())\n",
    "sns.countplot(x='Class', data=df)\n",
    "plt.title(\"Fraud (1) vs Non-Fraud (0) - Before SMOTE\")\n",
    "plt.savefig(f\"{output_viz_path}class_distribution_before_smote.png\")\n",
    "plt.close()\n",
    "\n",
    "# Feature histograms\n",
    "df[selected_features].hist(figsize=(20, 15), bins=30, edgecolor='black')\n",
    "plt.suptitle(\"Feature Histograms\", fontsize=16)\n",
    "plt.savefig(f\"{output_viz_path}feature_histograms.png\")\n",
    "plt.close()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "corr = df[selected_features].corr()\n",
    "sns.heatmap(corr, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.savefig(f\"{output_viz_path}feature_correlation_heatmap.png\")\n",
    "plt.close()\n",
    "\n",
    "# ========================= Indhuwara =========================\n",
    "# 6. Train/Test Split + Scaling\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Boxplot BEFORE SMOTE (example with 'Amount')\n",
    "train_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "train_df['Class'] = y_train.values\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x='Class', y='Amount', data=train_df)\n",
    "plt.title(\"Boxplot of 'Amount' BEFORE SMOTE\")\n",
    "plt.savefig(f\"{output_viz_path}amount_boxplot_before_smote.png\")\n",
    "plt.close()\n",
    "\n",
    "# ========================= Sandali =========================\n",
    "# 7. Apply SMOTE only on training set (Balancing Classes)\n",
    "print(\"\nApplying SMOTE to training set...\")\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Boxplot AFTER SMOTE\n",
    "train_res_df = pd.DataFrame(X_train_res, columns=X_train.columns)\n",
    "train_res_df['Class'] = y_train_res\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x='Class', y='Amount', data=train_res_df)\n",
    "plt.title(\"Boxplot of 'Amount' AFTER SMOTE\")\n",
    "plt.savefig(f\"{output_viz_path}amount_boxplot_after_smote.png\")\n",
    "plt.close()\n",
    "\n",
    "# Check class distributions\n",
    "print(\"\nClass distribution BEFORE SMOTE (Train):\n\", y_train.value_counts())\n",
    "print(\"\nClass distribution AFTER SMOTE (Train):\n\", pd.Series(y_train_res).value_counts())\n",
    "sns.countplot(x=y_train_res)\n",
    "plt.title(\"Fraud (1) vs Non-Fraud (0) - After SMOTE (Train)\")\n",
    "plt.savefig(f\"{output_viz_path}class_distribution_after_smote.png\")\n",
    "plt.close()\n",
    "\n",
    "# ========================= Shared (Final Checks – Whole Team) =========================\n",
    "# 8. Summary statistics\n",
    "print(\"\nSummary statistics:\n\", df.describe())\n",
    "\n",
    "# 9. Preprocessing Quality Check\n",
    "print(\"\n=== Preprocessing Quality Check ===\")\n",
    "print(f\"Training set shape after SMOTE: {X_train_res.shape}, Labels: {y_train_res.shape}\")\n",
    "print(\"NaN values in training features:\", np.isnan(X_train_res).sum())\n",
    "print(\"Infinite values in training features:\", np.isinf(X_train_res).sum())\n",
    "feature_variance = np.var(X_train_res, axis=0)\n",
    "low_var_features = np.where(feature_variance < 1e-6)[0]\n",
    "if len(low_var_features) > 0:\n",
    "    print(f\"⚠️ Low variance features detected at indices: {low_var_features}\")\n",
    "else:\n",
    "    print(\"✅ All features have acceptable variance.\")\n",
    "\n",
    "# 10. Multicollinearity check\n",
    "corr_matrix = pd.DataFrame(X_train_res).corr()\n",
    "high_corr = np.where((corr_matrix > 0.95) & (corr_matrix < 1.0))\n",
    "if len(high_corr[0]) > 0:\n",
    "    print(\"⚠️ Highly correlated features detected!\")\n",
    "else:\n",
    "    print(\"✅ No problematic correlations detected.\")"
   ],
   "id": "9c3aa0501c2a1b57",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 18) (58217433.py, line 18)",
     "output_type": "error",
     "traceback": [
      "  \u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 18\u001B[39m\n\u001B[31m    \u001B[39m\u001B[31mprint(\"\u001B[39m\n          ^\n\u001B[31mSyntaxError\u001B[39m\u001B[31m:\u001B[39m unterminated string literal (detected at line 18)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6117d88fb09c4ee5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
