{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-18T05:28:41.481454Z",
     "start_time": "2025-10-18T05:23:29.884503Z"
    }
   },
   "source": [
    "# ========================= Imports =========================\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ========================= Load Dataset =========================\n",
    "df = pd.read_csv(r\"C:\\Users\\NEVIN\\PycharmProjects\\DataPreprocessing\\Group_ID\\data\\raw\\creditcard.csv\")\n",
    "print(\"\\n=== Dataset Loaded ===\")\n",
    "\n",
    "# ========================= Handle Missing Values =========================\n",
    "for col in df.columns:\n",
    "    if df[col].dtype in ['float64', 'int64']:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    else:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# ========================= Encode Categorical Variables =========================\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "# ========================= Outlier Handling =========================\n",
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns.drop('Class', errors='ignore')\n",
    "for col in num_cols:\n",
    "    lower = df[col].quantile(0.01)\n",
    "    upper = df[col].quantile(0.99)\n",
    "    df[col] = np.clip(df[col], lower, upper)\n",
    "\n",
    "# ========================= Feature Engineering =========================\n",
    "if 'Amount' in df.columns and 'Time' in df.columns:\n",
    "    df['Amount_per_Time'] = df['Amount'] / (df['Time'] + 1)\n",
    "\n",
    "# ========================= Feature Selection =========================\n",
    "X_temp = df.drop('Class', axis=1)\n",
    "y_temp = df['Class']\n",
    "mi_scores = mutual_info_classif(X_temp, y_temp, random_state=42)\n",
    "mi_series = pd.Series(mi_scores, index=X_temp.columns).sort_values(ascending=False)\n",
    "selected_features = mi_series[mi_series > 0].index.tolist()\n",
    "\n",
    "X = df[selected_features]\n",
    "y = df['Class']\n",
    "\n",
    "# ========================= Train/Test Split + Scaling =========================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ========================= Train only on normal transactions =========================\n",
    "X_train_normal = X_train_scaled[y_train == 0]\n",
    "input_dim = X_train_normal.shape[1]\n",
    "\n",
    "# ========================= Manual Hyperparameter Tuning =========================\n",
    "param_grid = [\n",
    "    {'hidden1': 16, 'hidden2': 8, 'lr': 0.001, 'batch_size': 256},\n",
    "    {'hidden1': 32, 'hidden2': 16, 'lr': 0.001, 'batch_size': 256},\n",
    "    {'hidden1': 16, 'hidden2': 8, 'lr': 0.005, 'batch_size': 128},\n",
    "]\n",
    "\n",
    "best_threshold = None\n",
    "best_roc = 0\n",
    "best_model = None\n",
    "\n",
    "for params in param_grid:\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    encoded = Dense(params['hidden1'], activation='relu')(input_layer)\n",
    "    encoded = Dense(params['hidden2'], activation='relu')(encoded)\n",
    "    decoded = Dense(params['hidden1'], activation='relu')(encoded)\n",
    "    decoded = Dense(input_dim, activation='linear')(decoded)\n",
    "\n",
    "    autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=params['lr']), loss='mse')\n",
    "\n",
    "    autoencoder.fit(\n",
    "        X_train_normal, X_train_normal,\n",
    "        epochs=20,\n",
    "        batch_size=params['batch_size'],\n",
    "        shuffle=True,\n",
    "        validation_split=0.1,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Compute reconstruction error on test\n",
    "    X_test_pred = autoencoder.predict(X_test_scaled)\n",
    "    mse = np.mean(np.power(X_test_scaled - X_test_pred, 2), axis=1)\n",
    "\n",
    "    # Threshold from normal training data\n",
    "    X_train_pred = autoencoder.predict(X_train_normal)\n",
    "    mse_train = np.mean(np.power(X_train_normal - X_train_pred, 2), axis=1)\n",
    "    threshold = mse_train.mean() + 3 * mse_train.std()\n",
    "\n",
    "    # Predicted labels\n",
    "    y_pred = (mse > threshold).astype(int)\n",
    "\n",
    "    # Evaluate ROC-AUC\n",
    "    roc = roc_auc_score(y_test, mse)\n",
    "    print(f\"Params: {params}, ROC-AUC: {roc:.4f}\")\n",
    "\n",
    "    if roc > best_roc:\n",
    "        best_roc = roc\n",
    "        best_threshold = threshold\n",
    "        best_model = autoencoder\n",
    "\n",
    "# ========================= Final Evaluation =========================\n",
    "X_test_pred = best_model.predict(X_test_scaled)\n",
    "mse = np.mean(np.power(X_test_scaled - X_test_pred, 2), axis=1)\n",
    "y_pred = (mse > best_threshold).astype(int)\n",
    "\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "roc_auc = roc_auc_score(y_test, mse)\n",
    "print(f\"\\nROC-AUC Score: {roc_auc:.4f}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset Loaded ===\n",
      "\u001B[1m1781/1781\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 2ms/step\n",
      "\u001B[1m7108/7108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 2ms/step\n",
      "Params: {'hidden1': 16, 'hidden2': 8, 'lr': 0.001, 'batch_size': 256}, ROC-AUC: 0.9402\n",
      "\u001B[1m1781/1781\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 670us/step\n",
      "\u001B[1m7108/7108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 728us/step\n",
      "Params: {'hidden1': 32, 'hidden2': 16, 'lr': 0.001, 'batch_size': 256}, ROC-AUC: 0.9601\n",
      "\u001B[1m1781/1781\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 771us/step\n",
      "\u001B[1m7108/7108\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m11s\u001B[0m 2ms/step\n",
      "Params: {'hidden1': 16, 'hidden2': 8, 'lr': 0.005, 'batch_size': 128}, ROC-AUC: 0.9477\n",
      "\u001B[1m1781/1781\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 1ms/step\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9861    0.9928     56864\n",
      "           1     0.0938    0.8367    0.1687        98\n",
      "\n",
      "    accuracy                         0.9858     56962\n",
      "   macro avg     0.5468    0.9114    0.5808     56962\n",
      "weighted avg     0.9982    0.9858    0.9914     56962\n",
      "\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[56072   792]\n",
      " [   16    82]]\n",
      "\n",
      "ROC-AUC Score: 0.9601\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9b55ef8991da4252"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
