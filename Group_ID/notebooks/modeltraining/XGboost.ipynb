{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-18T03:35:39.752252Z",
     "start_time": "2025-10-18T03:34:33.461726Z"
    }
   },
   "source": [
    "# ========================= Imports =========================\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# ========================= Load Dataset =========================\n",
    "df = pd.read_csv(r\"C:\\Users\\NEVIN\\PycharmProjects\\DataPreprocessing\\Group_ID\\data\\raw\\creditcard.csv\")\n",
    "print(\"\\n=== Dataset Loaded ===\")\n",
    "\n",
    "# ========================= Handle Missing Values =========================\n",
    "if df.isnull().sum().sum() > 0:\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in ['float64', 'int64']:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "        else:\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# ========================= Encode Categorical Variables =========================\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "if len(categorical_cols) > 0:\n",
    "    le = LabelEncoder()\n",
    "    for col in categorical_cols:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# ========================= Outlier Handling =========================\n",
    "num_cols = df.select_dtypes(include=['float64', 'int64']).columns.drop('Class', errors='ignore')\n",
    "for col in num_cols:\n",
    "    lower = df[col].quantile(0.01)\n",
    "    upper = df[col].quantile(0.99)\n",
    "    df[col] = np.clip(df[col], lower, upper)\n",
    "\n",
    "# ========================= Feature Engineering =========================\n",
    "if 'Amount' in df.columns and 'Time' in df.columns:\n",
    "    df['Amount_per_Time'] = df['Amount'] / (df['Time'] + 1)\n",
    "\n",
    "# ========================= Feature Selection (Mutual Information) =========================\n",
    "X_temp = df.drop('Class', axis=1)\n",
    "y_temp = df['Class']\n",
    "mi_scores = mutual_info_classif(X_temp, y_temp, random_state=42)\n",
    "mi_series = pd.Series(mi_scores, index=X_temp.columns).sort_values(ascending=False)\n",
    "selected_features = mi_series[mi_series > 0].index.tolist()\n",
    "\n",
    "X = df[selected_features]\n",
    "y = df['Class']\n",
    "\n",
    "# ========================= Train/Test Split + Scaling =========================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ========================= Compute scale_pos_weight =========================\n",
    "neg, pos = np.bincount(y_train)\n",
    "scale_pos_weight = neg / pos\n",
    "\n",
    "# ========================= FAST SUBSET FOR HYPERPARAMETER TUNING =========================\n",
    "sample_size = int(0.1 * len(X_train_scaled))\n",
    "X_tune = X_train_scaled[:sample_size]\n",
    "y_tune = y_train[:sample_size]\n",
    "\n",
    "# ========================= Hyperparameter Tuning =========================\n",
    "xgb = XGBClassifier(\n",
    "    random_state=42,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    eval_metric='logloss',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'max_depth': [3, 5, 6],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "xgb_random = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=5,               # ultra-fast\n",
    "    scoring='roc_auc',\n",
    "    cv=2,                   # 2-fold CV\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n=== Running FAST Hyperparameter Tuning (on 10% sample) ===\")\n",
    "xgb_random.fit(X_tune, y_tune)\n",
    "\n",
    "print(\"\\n=== Best Parameters Found ===\")\n",
    "print(xgb_random.best_params_)\n",
    "\n",
    "# ========================= Retrain Final Model on Full Training Data =========================\n",
    "best_xgb = xgb_random.best_estimator_\n",
    "best_xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ========================= Predictions & Evaluation =========================\n",
    "y_pred = best_xgb.predict(X_test_scaled)\n",
    "y_pred_prob = best_xgb.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "print(f\"\\nROC-AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "# ========================= Feature Importance =========================\n",
    "feature_importance = pd.Series(best_xgb.feature_importances_, index=selected_features).sort_values(ascending=False)\n",
    "print(\"\\n=== XGBoost Feature Importance ===\")\n",
    "print(feature_importance)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset Loaded ===\n",
      "\n",
      "=== Running FAST Hyperparameter Tuning (on 10% sample) ===\n",
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "\n",
      "=== Best Parameters Found ===\n",
      "{'subsample': 0.8, 'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.05, 'gamma': 0.1, 'colsample_bytree': 0.6}\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9997    0.9994    0.9996     56864\n",
      "           1     0.7094    0.8469    0.7721        98\n",
      "\n",
      "    accuracy                         0.9991     56962\n",
      "   macro avg     0.8546    0.9232    0.8858     56962\n",
      "weighted avg     0.9992    0.9991    0.9992     56962\n",
      "\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[56830    34]\n",
      " [   15    83]]\n",
      "\n",
      "ROC-AUC Score: 0.9796\n",
      "\n",
      "=== XGBoost Feature Importance ===\n",
      "V14                0.327924\n",
      "V4                 0.150161\n",
      "V10                0.070812\n",
      "Amount             0.032151\n",
      "V11                0.030215\n",
      "V17                0.029575\n",
      "V8                 0.029288\n",
      "V20                0.026409\n",
      "V12                0.025175\n",
      "V3                 0.020685\n",
      "V19                0.019207\n",
      "V13                0.018553\n",
      "V21                0.016777\n",
      "V22                0.013549\n",
      "V26                0.012988\n",
      "V25                0.012782\n",
      "V18                0.012728\n",
      "V16                0.012370\n",
      "V7                 0.012365\n",
      "Time               0.012264\n",
      "V15                0.012232\n",
      "V28                0.012052\n",
      "V1                 0.011846\n",
      "V23                0.011496\n",
      "V27                0.011087\n",
      "V5                 0.010914\n",
      "Amount_per_Time    0.010559\n",
      "V6                 0.010068\n",
      "V9                 0.008885\n",
      "V24                0.007874\n",
      "V2                 0.007008\n",
      "dtype: float32\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3e1753162ed367c5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
